import os

localrules: copy_config
CONFIG_PATH = f"config_{'gpu' if config.get('gpu', '') == 'True' else 'cpu'}.yaml"

TRAIN_FILE = config.get("input", {}).get("data", "").get("train", "")
TEST_FILE = config.get("input", {}).get("data", "").get("test", "")
HP_DIR = config['refit']['hyperparams']
PREFIX = config["output"]["prefix"]
OUT_DIR = os.path.join(config["output"]["dir"], f'job_{PREFIX}')
PLATT_MODEL = (
    config['predict']['platt_model'] 
    if config['predict']['platt_model'] not in (None, "None") 
    else f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_shaprefit_plattscalemodel.json'
)

rule all:
    input:
        f'{OUT_DIR}/logs/config.yaml',  # Copy of config.yaml in logs dir
        f'{OUT_DIR}/refit/importances/{PREFIX}_train_refit_imp.csv', # train data: importance scores
        f'{OUT_DIR}/refit/importances/{PREFIX}_train_refit_shap_colnames.csv',
        directory(f'{OUT_DIR}/refit/importances/{PREFIX}_train_refit_shap_main.zarr'),
        f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_origrefit_xgbmodel.json', # train data: models
        f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_shaprefit_xgbmodel.json',
        f'{OUT_DIR}/refit/predictors/{PREFIX}_train_refit_used_cols.csv', # train data: predictors
        f'{OUT_DIR}/predict/predictions/{PREFIX}_test_predict_y_pred.csv', # test data: predictions
        f'{OUT_DIR}/predict/importances/{PREFIX}_test_predict_imp.csv', # test data: importance scores
        f'{OUT_DIR}/predict/importances/{PREFIX}_test_predict_shap_colnames.csv',
        directory(f'{OUT_DIR}/predict/importances/{PREFIX}_test_predict_shap_main.zarr')

rule copy_config:
    input:
        CONFIG_PATH  # Use the captured path
    params:
        outdir=f"{OUT_DIR}/logs"
    output:
        f"{OUT_DIR}/logs/config.yaml"
    shell:
        """
        mkdir -p {params.outdir}
        cp {input} {output}
        """

rule run_model_refit:
    input:
        TRAIN_FILE,
        HP_DIR
    params:
        infile=TRAIN_FILE,
        threads=config['refit']['cpu_threads'],
        time=config['refit']['time'],
        mem=config['refit']['mem'],
        workers=config['refit']['workers'],
        cv_folds=config['cv']['folds'],
        out=OUT_DIR,
        train_prefix=f'{PREFIX}_train_refit',
        dask_chunks=config['jobs']['dask_row_chunks'],
        hyperparams=HP_DIR,
        gpu=config['gpu'],
        gpu_resources=config['jobs']['gpu_resources'],
        xkey=config['jobs']['xkey'],
        ykey=config['jobs']['ykey'],
        worker_queue=config['jobs']['worker_queue'],
        gcc_module=config['env']['gcc_module'],
        cuda_module=config['env']['cuda_module'],
        conda_module=config['env']['conda_module'],
        conda_env=config['env']['conda_env'],
        tmp_dir=f"{config['jobs']['temp_dir']}/dask_temp/{PREFIX}",
        force_n_boosters=config['refit']['force_n_boosters'],
        cluster_type=config['jobs']['cluster_type']
    output:
        f'{OUT_DIR}/refit/importances/{PREFIX}_train_refit_imp.csv', # importance scores
        f'{OUT_DIR}/refit/importances/{PREFIX}_train_refit_shap_colnames.csv',
        directory(f'{OUT_DIR}/refit/importances/{PREFIX}_train_refit_shap_main.zarr'),
        f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_origrefit_xgbmodel.json', # models
        f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_shaprefit_xgbmodel.json',
        f'{OUT_DIR}/refit/predictors/{PREFIX}_train_refit_used_cols.csv', # predictors
        temp(directory(f"{config['jobs']['temp_dir']}/dask_temp/{PREFIX}")) # dask temp dir - to be deleted
    shell:
        """
        module purge

        echo -e "\n--> Loading Modules on Scheduler"

        if [[ "{params.gpu}" == "True" ]]; then
            echo -e "\n--> GPU version selected"
        else
            echo -e "\n--> CPU version selected"
        fi

        if [[ "{params.cluster_type}" == "local" ]]; then
            module load {params.gcc_module}
            module load {params.cuda_module}

            if [[ "{params.gpu}" == "True" ]]; then
                echo -e "\n--> Planning LocalCUDACluster"
                echo -e "\n################################################################################"
                echo -e "############################# Verifying GPU support ##############################"
                nvidia-smi
                echo -e "################################################################################"
                echo -e "################################################################################\n"
            else
                echo -e "\n--> Planning LocalCluster"
            fi
        else
            echo -e "\n--> Planning distributed SLURMCluster"
        fi

        module load {params.conda_module}
        conda activate {params.conda_env}

        # print node name for setting up dask dashboard
        echo -e "\n################################################################################"
        echo -e "############################# DASK DASHBOARD SETUP #############################"
        echo "  Running Dask scheduler on node ${{SLURMD_NODENAME}}"
        echo "  Paste command below into local terminal session to allow tunnelling for the dask dashboard:"
        echo "  'ssh -N -L 8787:${{SLURMD_NODENAME}}:8787 username@server'"
        echo "  paste address 'localhost:8787' in local browser session"
        echo -e "################################################################################"
        echo -e "################################################################################\n"

        python3 ../../scripts/refit.py \
            --in_ml {params.infile} \
            --n_threads_per_worker {params.threads} \
            --time_per_worker {params.time} \
            --mem_per_worker {params.mem} \
            --n_workers_in_cluster {params.workers} \
            --n_folds {params.cv_folds} \
            --out {params.out} \
            --prefix {params.train_prefix} \
            --local_dir {params.tmp_dir} \
            --row_chunk_size {params.dask_chunks} \
            --cluster {params.cluster_type} \
            --incremental_learning False \
            --incremental_start_round 0 \
            --incremental_n_boost_per_round 10 \
            --verbose True \
            --xgb_eval_metric logloss \
            --run_shap_main True \
            --run_shap_inter False \
            --hp_search_results {params.hyperparams} \
            --gpu {params.gpu} \
            --gpu_resources {params.gpu_resources} \
            --interface None \
            --gcc_module {params.gcc_module} \
            --cuda_module {params.cuda_module} \
            --conda_module {params.conda_module} \
            --conda_env {params.conda_env} \
            --xkey {params.xkey} \
            --ykey {params.ykey} \
            --worker_queue {params.worker_queue} \
            --n_booster_overide {params.force_n_boosters}
        """

rule run_model_predict:
    input:
        TEST_FILE,
        bst_col_path=f'{OUT_DIR}/refit/predictors/{PREFIX}_train_refit_used_cols.csv',
        bst_path=f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_shaprefit_xgbmodel.json'
    params:
        infile=TEST_FILE,
        bst_col_path=f'{OUT_DIR}/refit/predictors/{PREFIX}_train_refit_used_cols.csv',
        bst_path=f'{OUT_DIR}/refit/models/{PREFIX}_train_refit_shaprefit_xgbmodel.json',
        platt_model=PLATT_MODEL,
        threads=config['predict']['cpu_threads'],
        time=config['predict']['time'],
        mem=config['predict']['mem'],
        workers=config['predict']['workers'],
        gpu=config['gpu'],
        gpu_resources=config['jobs']['gpu_resources'],
        xkey=config['jobs']['xkey'],
        ykey=config['jobs']['ykey'],
        worker_queue=config['jobs']['worker_queue'],
        dask_chunks=config['jobs']['dask_row_chunks'],
        out=OUT_DIR,
        test_prefix=f'{PREFIX}_test_predict',
        gcc_module=config['env']['gcc_module'],
        cuda_module=config['env']['cuda_module'],
        conda_module=config['env']['conda_module'],
        conda_env=config['env']['conda_env'],
        tmp_dir=f"{config['jobs']['temp_dir']}/dask_temp/{PREFIX}",
        cluster_type=config['jobs']['cluster_type']
    output:
        temp(directory(f"{config['jobs']['temp_dir']}/dask_temp/{PREFIX}")), # temp dask files
        f'{OUT_DIR}/predict/predictions/{PREFIX}_test_predict_y_pred.csv', # predictions
        f'{OUT_DIR}/predict/importances/{PREFIX}_test_predict_imp.csv', # importance scores
        f'{OUT_DIR}/predict/importances/{PREFIX}_test_predict_shap_colnames.csv',
        directory(f'{OUT_DIR}/predict/importances/{PREFIX}_test_predict_shap_main.zarr')
    shell:
        """
        # load module and env
        module purge

        echo -e "\n--> Loading Modules on Scheduler"

        if [[ "{params.gpu}" == "True" ]]; then
            echo -e "\n--> GPU version selected"
        else
            echo -e "\n--> CPU version selected"
        fi

        if [[ "{params.cluster_type}" == "local" ]]; then
            module load {params.gcc_module}
            module load {params.cuda_module}

            if [[ "{params.gpu}" == "True" ]]; then
                echo -e "\n--> Planning LocalCUDACluster"
                echo -e "\n################################################################################"
                echo -e "############################# Verifying GPU support ##############################"
                nvidia-smi
                echo -e "################################################################################"
                echo -e "################################################################################\n"
            else
                echo -e "\n--> Planning LocalCluster"
            fi
        else
            echo -e "\n--> Planning distributed SLURMCluster"
        fi

        module load {params.conda_module}
        conda activate {params.conda_env}

        # print node name for setting up dask dashboard
        echo -e "\n################################################################################"
        echo -e "############################# DASK DASHBOARD SETUP #############################"
        echo "  Running Dask scheduler on node ${{SLURMD_NODENAME}}"
        echo "  Paste command below into local terminal session to allow tunnelling for the dask dashboard:"
        echo "  'ssh -N -L 8787:${{SLURMD_NODENAME}}:8787 username@server'"
        echo "  paste address 'localhost:8787' in local browser session"
        echo -e "################################################################################"
        echo -e "################################################################################\n"

        python3 ../../scripts/predict.py \
            --in_ml {params.infile} \
            --used_cols {params.bst_col_path} \
            --bst_path {params.bst_path} \
            --cluster {params.cluster_type} \
            --n_threads_per_worker {params.threads} \
            --time_per_worker {params.time} \
            --mem_per_worker {params.mem} \
            --n_workers_in_cluster {params.workers} \
            --out {params.out} \
            --prefix {params.test_prefix} \
            --local_dir {params.tmp_dir} \
            --row_chunk_size {params.dask_chunks} \
            --run_shap_main True \
            --run_shap_inter False \
            --platt_scale_model {params.platt_model} \
            --gpu {params.gpu} \
            --gpu_resources {params.gpu_resources} \
            --interface None \
            --gcc_module {params.gcc_module} \
            --cuda_module {params.cuda_module} \
            --conda_module {params.conda_module} \
            --conda_env {params.conda_env} \
            --xkey {params.xkey} \
            --ykey {params.ykey} \
            --worker_queue {params.worker_queue}
        """